{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method Chaining\n",
    "\n",
    "Method chaining, where you call methods on an object one after another, is in vogue at the moment.\n",
    "It's always been a style of programming that's been possible with pandas,\n",
    "and over the past several releases, we've added methods that enable even more chaining.\n",
    "\n",
    "- [assign](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.assign.html) (0.16.0): For adding new columns to a DataFrame in a chain (inspired by dplyr's `mutate`)\n",
    "- [pipe](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pipe.html) (0.16.2): For including user-defined methods in method chains.\n",
    "- [rename](http://pandas.pydata.org/pandas-docs/version/0.18.0/whatsnew.html#changes-to-rename) (0.18.0): For altering axis names (in additional to changing the actual labels as before).\n",
    "- [Window methods](http://pandas.pydata.org/pandas-docs/version/0.18.0/whatsnew.html#window-functions-are-now-methods) (0.18): Took the top-level `pd.rolling_*` and `pd.expanding_*` functions and made them `NDFrame` methods with a `groupby`-like API.\n",
    "- [Resample](http://pandas.pydata.org/pandas-docs/version/0.18.0/whatsnew.html#resample-api) (0.18.0) Added a new `groupby`-like API\n",
    "- [.where/mask/Indexers accept Callables](https://github.com/pydata/pandas/pull/12539) (0.18.1): In the next release you'll be able to pass a callable to the indexing methods, to be evaluated within the DataFrame's context (like `.query`, but with code instead of strings).\n",
    "\n",
    "My scripts will typically start off with large-ish chain at the start getting things into a manageable state.\n",
    "It's good to have the bulk of your munging done with right away so you can start to do Scienceâ„¢:\n",
    "\n",
    "Here's a quick example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style='ticks', context='talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(fp):\n",
    "    df = pd.read_csv(fp).rename(columns=str.lower)\n",
    "    cols = [col for col in df.columns if col.startswith(\"unnamed:\")]\n",
    "    for col in cols:\n",
    "        df = df.drop(col, axis=1)\n",
    "    df = (df.pipe(extract_city_name)\n",
    "            .pipe(time_to_datetime, ['dep_time', 'arr_time', 'crs_arr_time', 'crs_dep_time'])\n",
    "            .assign(fl_date=lambda x: pd.to_datetime(x['fl_date']),\n",
    "                    dest=lambda x: pd.Categorical(x['dest']),\n",
    "                    origin=lambda x: pd.Categorical(x['origin']),\n",
    "                    tail_num=lambda x: pd.Categorical(x['tail_num']),\n",
    "                    unique_carrier=lambda x: pd.Categorical(x['unique_carrier']),\n",
    "                    cancellation_code=lambda x: pd.Categorical(x['cancellation_code'])))\n",
    "    return df\n",
    "\n",
    "def extract_city_name(df):\n",
    "    '''\n",
    "    Chicago, IL -> Chicago for origin_city_name and dest_city_name\n",
    "    '''\n",
    "    cols = ['origin_city_name', 'dest_city_name']\n",
    "    city = df[cols].apply(lambda x: x.str.extract(\"(.*), \\w{2}\", expand=False))\n",
    "    df = df.copy()\n",
    "    df[['origin_city_name', 'dest_city_name']] = city\n",
    "    return df\n",
    "\n",
    "def time_to_datetime(df, columns):\n",
    "    '''\n",
    "    Combine all time items into datetimes.\n",
    "\n",
    "    2014-01-01,0914 -> 2014-01-01 09:14:00\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    def converter(col):\n",
    "        timepart = (col.astype(str)\n",
    "                       .str.replace('\\.0$', '')  # NaNs force float dtype\n",
    "                       .str.pad(4, fillchar='0'))\n",
    "        return pd.to_datetime(df['fl_date'] + ' ' +\n",
    "                               timepart.str.slice(0, 2) + ':' +\n",
    "                               timepart.str.slice(2, 4),\n",
    "                               errors='coerce')\n",
    "    df[columns] = df[columns].apply(converter)\n",
    "    return df\n",
    "\n",
    "output = 'data/flights.h5'\n",
    "\n",
    "if not os.path.exists(output):\n",
    "    import glob\n",
    "    df = read(glob.glob(\"data/*_ONTIME.csv\")[0])\n",
    "    df.to_hdf(output, 'flights', format='table')\n",
    "else:\n",
    "    df = pd.read_hdf(output, 'flights')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find method chains readable, though some people don't.\n",
    "Both the code and the flow of execution are from top to bottom, and the function parameters are always near the function itself, unlike with heavily nested function calls.\n",
    "\n",
    "My favorite example demonstrating this comes from [Jeff Allen](http://trestletech.com/wp-content/uploads/2015/07/dplyr.pdf) (pdf). Compare these two ways of telling the same story:\n",
    "\n",
    "```R\n",
    "tumble_after(\n",
    "    broke(\n",
    "        fell_down(\n",
    "            fetch(went_up(jack_jill, \"hill\"), \"water\"),\n",
    "            jack),\n",
    "        \"crown\"),\n",
    "    \"jill\"\n",
    ")\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```R\n",
    "jack_jill %>%\n",
    "    went_up(\"hill\") %>%\n",
    "    fetch(\"water\") %>%\n",
    "    fell_down(\"jack\") %>%\n",
    "    broke(\"crown\") %>%\n",
    "    tumble_after(\"jill\")\n",
    "```\n",
    "\n",
    "Even if you weren't aware that in R `%>%` (pronounced *pipe*) calls the function on the right with the thing on the left as an argument, you can still make out what's going on. Compare that with the first style, where you need to unravel the code to figure out the order of execution and which arguments are being passed where.\n",
    "\n",
    "Admittedly, you probably wouldn't write the first one.\n",
    "It'd be something like\n",
    "\n",
    "```python\n",
    "on_hill = went_up(jack_jill, 'hill')\n",
    "with_water = fetch(on_hill, 'water')\n",
    "fallen = fell_down(with_water, 'jack')\n",
    "broken = broke(fallen, 'jack')\n",
    "after = tmple_after(broken, 'jill')\n",
    "```\n",
    "\n",
    "I don't like this version because I have to spend time coming up with appropriate names for variables.\n",
    "That's bothersome when we don't *really* care about the `on_hill` variable. We're just passing it into the next step.\n",
    "\n",
    "A fourth way of writing the same story may be available. Suppose you owned a `JackAndJill` object, and could define the methods on it. Then you'd have something like R's `%>%` example.\n",
    "\n",
    "```python\n",
    "jack_jill = JackAndJill()\n",
    "(jack_jill.went_up('hill')\n",
    "    .fetch('water')\n",
    "    .fell_down('jack')\n",
    "    .broke('crown')\n",
    "    .tumble_after('jill')\n",
    ")\n",
    "```\n",
    "\n",
    "But the problem is you don't own the `ndarray` or `DataFrame` or [`DataArray`](http://xarray.pydata.org/en/stable/data-structures.html#dataarray), and the exact method you want may not exist.\n",
    "Monekypatching on your own methods is fragile.\n",
    "It's not easy to correctly subclass pandas' DataFrame to extend it with your own methods.\n",
    "Composition, where you create a class that holds onto a DataFrame internally, may be fine for your own code, but it won't interact well with the rest of the ecosystem so your code will be littered with lines extracting and repacking the underlying DataFrame.\n",
    "\n",
    "Perhaps you could submit a pull request to pandas implementing your method.\n",
    "But then you'd need to convince the maintainers that it's broadly useful enough to merit its inclusion (and worth their time to maintain it). And `DataFrame` has something like 250+ methods, so we're reluctant to add more.\n",
    "\n",
    "Enter [`DataFrame.pipe`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pipe.html). All the benefits of having your specific function as a method on the DataFrame, without us having to maintain it, and without it overloading the already large pandas API. A win for everyone.\n",
    "\n",
    "```python\n",
    "jack_jill = pd.DataFrame()\n",
    "(jack_jill.pipe(went_up, 'hill')\n",
    "    .pipe(fetch, 'water')\n",
    "    .pipe(fell_down, 'jack')\n",
    "    .pipe(broke, 'crown')\n",
    "    .pipe(tumble_after, 'jill')\n",
    ")\n",
    "```\n",
    "\n",
    "This really is just right-to-left function execution. The first argument to `pipe`, a callable, is called with the DataFrame on the left as its first argument, and any additional arguments you specify.\n",
    "\n",
    "I hope the analogy to data analysis code is clear.\n",
    "Code is read more often than it is written.\n",
    "When you or your coworkers or research partners have to go back in two months to update your script, having the story of raw data to results be told as clearly as possible will save you time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costs\n",
    "\n",
    "One drawback to excessively long chains is that debugging can be harder.\n",
    "If something looks wrong at the end, you don't have intermediate values to inspect. There's a close parallel here to python's generators. Generators are great for keeping memory consumption down, but they can be hard to debug since values are consumed.\n",
    "\n",
    "For my typical exploratory workflow, this isn't really a big problem. I'm working with a single dataset that isn't being updated, and the path from raw data to usuable data isn't so large that I can't drop an `import pdb; pdb.set_trace()` in the middle of my code to poke around.\n",
    "\n",
    "For large workflows, you'll probably want to move away from pandas to something more structured, like [Airflow](http://pythonhosted.org/airflow/) or [Luigi](http://luigi.readthedocs.org/en/stable/index.html).\n",
    "\n",
    "When writing medium sized [ETL](https://en.wikipedia.org/wiki/Extract,_transform,_load) jobs in python that will be run repeatedly, I'll use decorators to inspect and log properties about the DataFrames at each step of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from functools import wraps\n",
    "import logging\n",
    "\n",
    "def log_shape(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        result = func(*args, **kwargs)\n",
    "        logging.info(\"%s,%s\" % (func.__name__, result.shape))\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def log_dtypes(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        result = func(*args, **kwargs)\n",
    "        logging.info(\"%s,%s\" % (func.__name__, result.dtypes))\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@log_shape\n",
    "@log_dtypes\n",
    "def load(fp):\n",
    "    df = pd.read_csv(fp, index_col=0, parse_dates=True)\n",
    "\n",
    "@log_shape\n",
    "@log_dtypes\n",
    "def update_events(df, new_events):\n",
    "    df.loc[new_events.index, 'foo'] = new_events\n",
    "    return df\n",
    "```\n",
    "\n",
    "This plays nicely with [`engarde`](http://engarde.readthedocs.org), a little library I wrote to validate data as it flows through the pipeline (it essentialy turns those logging statements into excpetions if something looks wrong)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inplace?\n",
    "\n",
    "Most pandas methods have an `inplace` keyword that's `False` by default.\n",
    "In general, you shouldn't do inplace operations.\n",
    "\n",
    "First, if you like method chains then you simply can't use inplace since the return value is `None`, terminating the chain.\n",
    "\n",
    "Second, I suspect people have a mental model of `inplace` operations happening, you know, inplace. That is, extra memory doesn't need to be allocated for the result. [But that might not actually be true](http://stackoverflow.com/a/22533110).\n",
    "Quoting Jeff Reback from that answer\n",
    "\n",
    "> Their is **no guarantee** that an inplace operation is actually faster. Often they are actually the same operation that works on a copy, but the top-level reference is reassigned.\n",
    "\n",
    "That is, the pandas code might look something like this\n",
    "\n",
    "```python\n",
    "def dataframe_method(self, inplace=False):\n",
    "    data = self.copy()  # regardless of inplace\n",
    "    result = ...\n",
    "    if inplace:\n",
    "        self._update_inplace(data)\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "```\n",
    "\n",
    "There's a lot of defensive copying in pandas.\n",
    "Part of this comes down to pandas being built on top of NumPy, and not having full control over how memory is handled and shared.\n",
    "We saw it above when we defined our own functions `extract_city_name` and `time_to_datetime`.\n",
    "Without the `copy`, adding the columns would modify the input DataFrame, which just isn't polite.\n",
    "\n",
    "Finally, inplace operations don't make sense in projects like [ibis](http://www.ibis-project.org) or [dask](http://dask.pydata.org/en/latest/), where you're manipulating expressions or building up a DAG of tasks to be executed, rather than manipulating the data directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application\n",
    "\n",
    "I feel like we haven't done much coding, mostly just me shouting from the top of a soapbox (sorry about that).\n",
    "Let's do some exploratory analysis.\n",
    "\n",
    "What does the daily flight pattern look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does a plane with multiple flights on the same day get backed up, causing later flights to be delayed more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'png'\n",
    "flights = (df[['fl_date', 'tail_num', 'dep_time', 'dep_delay']]\n",
    "           .dropna()\n",
    "           .sort_values('dep_time')\n",
    "           .loc[lambda x: x.dep_delay < 500]\n",
    "           .assign(turn = lambda x:\n",
    "                x.groupby(['fl_date', 'tail_num'])\n",
    "                 .dep_time\n",
    "                 .transform('rank').astype(int)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.boxplot(x='turn', y='dep_delay', data=flights, ax=ax)\n",
    "ax.set_ylim(-50, 50)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't really look like it. Maybe other planes are swapped in when one gets delayed,\n",
    "but we don't have data on *scheduled* flights per plane.\n",
    "\n",
    "Do flights later in the day have longer delays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "(df[['fl_date', 'tail_num', 'dep_time', 'dep_delay']]\n",
    "    .dropna()\n",
    "    .assign(hour=lambda x: x.dep_time.dt.hour)\n",
    "    .query('5 < dep_delay < 600')\n",
    "    .pipe((sns.boxplot, 'data'), 'hour', 'dep_delay'))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There could be something here. I didn't show it here since I filtered them out,\n",
    "but the vast majority of flights do leave on time.\n",
    "\n",
    "Thanks for reading!\n",
    "This section was a bit more abstract, since we were talking about styles\n",
    "of coding rather than how to actually accomplish tasks.\n",
    "I'm sometimes guilty of putting too much work into making my data wrangling code look nice and feel correct, at the expense of actually analyzing the data.\n",
    "This isn't a competition to have the best or cleanest pandas code; pandas is always just a means to the end that is your research or business problem.\n",
    "Thanks for indulging me.\n",
    "Next time we'll talk about a much more practical topic: performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
